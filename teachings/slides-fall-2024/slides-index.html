<!--                 <!-- week 3 -->
                <td class="schedules">Week 3</td>
                <td class="schedules">
                    <p class="red">Text pre-processing (Stop Words, Bag-of-Words, TF-IDF, POS Tagging, NER)<br></p>
                    <div class="links">
                        [<a href="NLP-Lecture-03.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules">
                    Suggested Readings and Hands-on:
                    <br>
                      <div class="links">
                        <ol type="1">
                            <li> <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Language Models (Textbook Chapter)</a></li>   
                        </ol>
                      </div>
                </td>
            </tr>
            <tr>
                <!-- week 4 -->
                <td class="schedules">Week 4</td>
                <td class="schedules">
                    <p class="red">Distributional semantics, Vector Embeddings<br></p>
                    <div class="links">
                        [<a href="NLP-Lecture-04.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules"> 
                        Assignment 2 Released!
                        <br>
                        <br>
                        Suggested Readings and Hands-on:
                        <br>
                          <div class="links">
                            <ol type="1">
                                <li> <a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">Vector Semantics and Embeddings (Textbook Chapter)</a></li>
                            </ol>
                          </div>
                      </td> 
            </tr>
             <tr>
                <!-- Week 5 -->
                <td class="schedules">Week 5</td>
                <td class="schedules">
                    <p class="red">Language Models-Probabilistic Language Modeling<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-05.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules"> Suggested Readings and Hands-on:
                    <br>
                      <div class="links">
                        <ol type="1">
                            <li> <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Language models (Textbook Chapter)</a></li>
                            <li><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Pytorch Basics</a></li>
                        </ol>
                      </div>
                  </td> 
            </tr>
            <tr>
                <!-- Week 6 -->
                <td class="schedules">Week 6</td>
                <td class="schedules">
                    <p class="red">Neural Networks and Neural Language Modeling<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-06.pdf">Lecture Slides</a>]
                      
                    </div>
                </td>
                <td class="schedules"> Suggested Readings and Hands-on:
                    <br>
                      <div class="links">
                        <ol type="1">
                            <li> <a href="https://web.stanford.edu/~jurafsky/slp3/7.pdf">Neural Networks and Neural Language Models (Textbook Chapter)</a></li>
                            <li><a href="https://github.com/hunkim/PytorchZeroToAll">PyTorch Hands-on Tutorials</a></li>
                            <li><a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes03-neuralnets.pdf">Neural Networks, Backpropagation [Notes-CS224n]</a></li>
                        </ol>
                      </div>
                  </td> 
            </tr>
            <tr>
                <!-- Week 7 -->
                <td class="schedules">Week 7</td>
                <td class="schedules">
                    <p class="red">Recurrent Neural Networks, LSTM<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-07.pdf">Lecture Slides</a>]
                        [<a href="lec02_rnn.pdf">RNN Slides</a>]
                    </div>
                </td>
                <td class="schedules">Suggested Readings and Hands-on:
                  <br>
                    <div class="links">
                        <ol type="1">
                            <li><a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf">RNNs and LSTMs (Textbook Chapter)</a></li>
                            <li><a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf">Language Models, RNN and LSTM [CS224n Lecture Notes]</a></li>
                            <li><a href="https://drive.google.com/drive/folders/0B41Zbb4c8HVyUndGdGdJSXd5d3M?resourcekey=0-s90CYmIbmbqbO1Mvtwmlog">RNN PyTorch Slides & Implementation</a></li>
                            <li><a href=" https://arxiv.org/pdf/1211.5063.pdf ">On the difficulty of training Recurrent Neural Networks [Research Paper][Additional]</a></li>
                            <li><a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/lectures/vanishing_grad_example.html">Vanishing and Exploding gradients (Colab Notebook)</a></li>
                        </ol>
                    </div>
                </td> 
            </tr>   
               <tr>


                <!-- Week 8 -->
                <td class="schedules">Week 8</td>
                <td class="schedules">
                    <p class="red">Advanced topics - Encoder Decoder Models, Attention<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-08_updated.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules">Suggested Readings and Hands-on:
                  <br>
                    <div class="links">
                        <ol type="1">
                            <li><a href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">Transformers (Textbook Chapter)</a></li>
                        </ol>
                    </div>
                </td> 
            </tr>   
            <!--WEEK 9 -->
            <tr>
                <td class="schedules">Week 9</td>
                <td class="schedules">
                    <p class="red">Advanced topics - Multi-head attention, Transformers<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-09.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules">Suggested Readings and Hands-on:
                  <br>
                    <div class="links">
                        <ol type="1">
                            <li><a href="https://github.com/jessevig/bertviz">BERT Visualization</a></li>
                        </ol>
                    </div>
                </td> 
            </tr> 
            <!---WEEK 10-->
            <tr>
                <td class="schedules">Week 10</td>
                <td class="schedules">
                    <p class="red">Advanced topics - BLEU Score, Introduction to LLM's Pretraining, Fine-tuning<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-10.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules"> Advanced topics - Suggested Readings and Hands-on:
                  <br>
                    <div class="links">
                        <ol type="1">
                            <li><a href=" https://jalammar.github.io/illustrated-transformer/"> The Illustrated Transformer by Jay Alammar</a></li>
                            <li><a href="https://arxiv.org/pdf/1706.03762">Attention is all you Need [Research Paper]</a></li>
                            <li><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html#attention-visualization">Attention Visualization</a></li>
                        </ol>
                    </div>
                </td> 
            </tr> 
            <!-- Week 11 -->
            <tr>
                <td class="schedules">Week 11</td>
                <td class="schedules">
                    <p class="red"> Advanced topics - MLM, BERT and NLP Applications<br></p>
                    <br>
                    <div class="links">
                        [<a href="NLP-Lecture-11.pdf">Lecture Slides</a>]
                    </div>
                </td>
                <td class="schedules">Suggested Readings and Hands-on:
                  <br>
                    <div class="links">
                        <ol type="1">
                            <li><a href="https://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. by Jay Alammar</a></li>
                            <li><a href="https://arxiv.org/pdf/1810.04805">BERT [Research Paper]</a></li>
                            <li><a href="https://huggingface.co/docs/transformers/model_doc/bert">Hugging Face - BERT</a></li>
                        </ol>
                    </div>
                </td> 
            </tr>  -->
